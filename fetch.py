#!/usr/bin/env python3
"""
X-Reader: X/Twitter å†…å®¹æŠ“å–å·¥å…·
ç»“åˆ x-tweet-fetcher å’Œ FxEmbed
æ”¯æŒï¼šæ¨æ–‡ã€é•¿æ¨æ–‡ã€X Article
"""

import argparse
import json
import os
import re
import sys
import urllib.parse
from datetime import datetime
from pathlib import Path

import requests
from bs4 import BeautifulSoup


class XReader:
    """X/Twitter å†…å®¹è¯»å–å™¨"""
    
    def __init__(self, data_dir="data"):
        self.data_dir = Path(data_dir)
        self.json_dir = self.data_dir / "json"
        self.markdown_dir = self.data_dir / "markdown"
        self.json_dir.mkdir(parents=True, exist_ok=True)
        self.markdown_dir.mkdir(parents=True, exist_ok=True)
    
    def extract_tweet_id(self, url):
        """ä» URL ä¸­æå–æ¨æ–‡ ID"""
        patterns = [
            r'twitter\.com/\w+/status/(\d+)',
            r'x\.com/\w+/status/(\d+)',
            r'twitter\.com/\w+/(\d+)',
            r'x\.com/\w+/(\d+)',
        ]
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        return None
    
    def get_fxembed_url(self, url):
        """è½¬æ¢ä¸º FxEmbed URL ç”¨äºåµŒå…¥ Discord"""
        result = url
        if 'x.com' in result:
            result = result.replace('x.com', 'fixupx.com')
        elif 'twitter.com' in result:
            result = result.replace('twitter.com', 'fxtwitter.com')
        return result
    
    def fetch_tweet(self, url, text_only=False):
        """è·å–æ¨æ–‡å†…å®¹"""
        tweet_id = self.extract_tweet_id(url)
        if not tweet_id:
            print(f"æ— æ³•ä» URL ä¸­æå–æ¨æ–‡ ID: {url}")
            return None
        
        # ä½¿ç”¨ FxTwitter API (å…¬å¼€ APIï¼Œæ— éœ€è®¤è¯)
        api_url = f"https://api.fxtwitter.com/status/{tweet_id}"
        
        try:
            response = requests.get(api_url, timeout=30)
            response.raise_for_status()
            data = response.json()
            return data
        except requests.RequestException as e:
            print(f"è·å–æ¨æ–‡å¤±è´¥: {e}")
            return None
    
    def parse_tweet(self, data):
        """è§£ææ¨æ–‡æ•°æ®"""
        if not data or 'tweet' not in data:
            return None
        
        tweet = data['tweet']
        author = tweet.get('author', {})
        
        result = {
            'id': tweet.get('id'),
            'url': tweet.get('url'),
            'text': tweet.get('text'),
            'raw_text': tweet.get('raw_text', {}).get('text', ''),
            'created_at': tweet.get('created_at'),
            'author': {
                'id': author.get('id'),
                'name': author.get('name'),
                'username': author.get('screen_name'),
                'avatar_url': author.get('avatar_url'),
                'verified': author.get('verified', False),
                'blue': author.get('blue', False),
            },
            'stats': {
                'likes': tweet.get('likes'),
                'retweets': tweet.get('retweets'),
                'replies': tweet.get('replies'),
                'views': tweet.get('views'),
            },
            'media': tweet.get('media', []),
            'entities': tweet.get('entities', {}),
            'is_note_tweet': tweet.get('is_note_tweet', False),
        }
        
        # å¤„ç† X Article
        if tweet.get('article'):
            result['article'] = self.parse_article(tweet['article'])
        
        return result
    
    def parse_article(self, article):
        """è§£æ X Article å†…å®¹"""
        if not article:
            return None
        
        # è§£æ blocks ä¸ºçº¯æ–‡æœ¬
        content_text = ""
        blocks = article.get('content', {}).get('blocks', [])
        for block in blocks:
            block_type = block.get('type', '')
            block_text = block.get('text', '')
            
            if block_type == 'header-one':
                content_text += f"# {block_text}\n\n"
            elif block_type == 'header-two':
                content_text += f"## {block_text}\n\n"
            elif block_type == 'blockquote':
                content_text += f"> {block_text}\n\n"
            elif block_type == 'unstyled':
                content_text += f"{block_text}\n\n"
            elif block_type == 'atomic':
                # å›¾ç‰‡/åª’ä½“
                media = block.get('data', {})
                if media.get('entityKey'):
                    content_text += f"[åª’ä½“å†…å®¹]\n\n"
            else:
                if block_text:
                    content_text += f"{block_text}\n\n"
        
        return {
            'id': article.get('id'),
            'title': article.get('title'),
            'preview_text': article.get('preview_text'),
            'content_text': content_text.strip(),
            'created_at': article.get('created_at'),
            'blocks': blocks,
        }
    
    def to_markdown(self, parsed):
        """è½¬æ¢ä¸º Markdown æ ¼å¼"""
        if not parsed:
            return None
        
        md = []
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ X Article
        article = parsed.get('article')
        if article:
            # X Article æ ¼å¼
            md.append(f"# {article.get('title', 'Untitled')}")
            md.append("")
            md.append(f"*{parsed['author']['name']}*")
            md.append("")
            md.append("---")
            md.append("")
            md.append(article.get('content_text', ''))
            md.append("")
            md.append("---")
            md.append(f"ğŸ”— [æŸ¥çœ‹åŸæ–‡]({parsed['url']})")
            return "\n".join(md)
        
        # æ™®é€šæ¨æ–‡æ ¼å¼
        author = parsed['author']
        badge = " âœ…" if author.get('verified') else ""
        if author.get('blue'):
            badge += " ğŸ’™"
        
        md.append(f"## ğŸ¦ {author['name']}{badge}")
        md.append(f"**@{author['username']}**")
        md.append("")
        
        # æ­£æ–‡ - ä¼˜å…ˆä½¿ç”¨ raw_text
        text = parsed.get('raw_text') or parsed.get('text', '')
        if text:
            # å¤„ç†æåŠã€è¯é¢˜æ ‡ç­¾ã€é“¾æ¥
            text = re.sub(r'@(\w+)', r'**@\1**', text)
            text = re.sub(r'#(\w+)', r'**#\1**', text)
            text = re.sub(r'https?://\S+', r'', text)  # ç§»é™¤é“¾æ¥
            md.append(text)
            md.append("")
        
        # ç»Ÿè®¡æ•°æ®
        stats = parsed['stats']
        stats_str = []
        if stats.get('likes'):
            stats_str.append(f"â¤ï¸ {stats['likes']:,}")
        if stats.get('retweets'):
            stats_str.append(f"ğŸ” {stats['retweets']:,}")
        if stats.get('replies'):
            stats_str.append(f"ğŸ’¬ {stats['replies']:,}")
        if stats.get('views'):
            stats_str.append(f"ğŸ‘ï¸ {stats['views']:,}")
        
        if stats_str:
            md.append(" | ".join(stats_str))
            md.append("")
        
        # æ—¶é—´
        if parsed.get('created_at'):
            md.append(f"*å‘å¸ƒæ—¶é—´: {parsed['created_at']}*")
        
        # åŸæ–‡é“¾æ¥
        md.append("")
        md.append(f"ğŸ”— [æŸ¥çœ‹åŸæ–‡]({parsed['url']})")
        
        return "\n".join(md)
    
    def save(self, url, markdown=True, json_save=True):
        """ä¿å­˜æ¨æ–‡å†…å®¹"""
        data = self.fetch_tweet(url)
        if not data:
            return None
        
        parsed = self.parse_tweet(data)
        if not parsed:
            return None
        
        tweet_id = parsed['id']
        filename = f"tweet_{tweet_id}"
        
        # ä¿å­˜ JSON
        if json_save:
            json_path = self.json_dir / f"{filename}.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"JSON å·²ä¿å­˜: {json_path}")
        
        # ä¿å­˜ Markdown
        if markdown:
            md_content = self.to_markdown(parsed)
            md_path = self.markdown_dir / f"{filename}.md"
            with open(md_path, 'w', encoding='utf-8') as f:
                f.write(md_content)
            print(f"Markdown å·²ä¿å­˜: {md_path}")
        
        return parsed


def main():
    parser = argparse.ArgumentParser(description="X-Reader: X/Twitter å†…å®¹æŠ“å–å·¥å…·")
    parser.add_argument("--url", help="æ¨æ–‡ URL")
    parser.add_argument("--markdown", action="store_true", help="ä¿å­˜ä¸º Markdown")
    parser.add_argument("--text-only", action="store_true", help="ä»…æ–‡æœ¬è¾“å‡º")
    parser.add_argument("--embed", action="store_true", help="æ˜¾ç¤º Discord åµŒå…¥é“¾æ¥")
    parser.add_argument("--output-dir", default="data", help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    if not args.url:
        print("è¯·æä¾› URL: python3 fetch.py --url <url>")
        sys.exit(1)
    
    reader = XReader(args.output_dir)
    
    # æ˜¾ç¤ºåµŒå…¥é“¾æ¥
    if args.embed:
        embed_url = reader.get_fxembed_url(args.url)
        print(f"Discord åµŒå…¥é“¾æ¥:")
        print(f"<{embed_url}>")
        return
    
    # è·å–å¹¶ä¿å­˜
    parsed = reader.save(args.url, markdown=args.markdown)
    
    if parsed and args.text_only:
        print(reader.to_markdown(parsed))


if __name__ == "__main__":
    main()
